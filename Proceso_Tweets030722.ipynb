{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18dbf090",
   "metadata": {},
   "source": [
    "<h3>En estas dos celdas se genera el método para recolectar los tuits y almacenarlos en un .csv</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dfed3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "column_names = ['user', 'date', 'content', 'user_location']\n",
    "dftemp = pd.DataFrame(columns = column_names)\n",
    "loc = '19.3206553, -99.1526775, 40km'\n",
    "\n",
    "terms = [\"COVID\", \"COVID19\", \"COVID-19\", \"Coronavirus\", \"Pandemia\", \"Cubrebocas\", \"Sana Distancia\",\"#COVID\", \"#COVID19\",\n",
    "         \"#COVID-19\", \"#Coronavirus\", \"#Pandemia\", \"#Cubrebocas\", \"#SanaDistancia\", \"#Delta\", \"AMLO\", \"#AstraZeneca\", \n",
    "        \"#Vacuna\", \"#Vacunación\", \"#Pfizer\", \"#Biontech\", \"Vacuna\", \"Vacunación\", \"Pfizer\", \"vacuna covid\", \"#vacunacovid\",\n",
    "        \"Astra Zeneca\", \"#Moderna\", \"#Vacunate\", \"#LavadoDeManos\", \"#UsaCubrebocas\", \"Janssen\", \"#Janssen\", \"#johnsonandjohnson\",\n",
    "        \"Sputnik V\", \"#SputnikV\", \"Cansino\", \"#Cansino\", \"Sinovac\", \"#Sinovac\", \"Omicron\", \"#Omicron\",\n",
    "        \"test\", \"tests\", \"cuarentena\", \"quinta ola\", \"#quintaola\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "desde = '2022-03-08'\n",
    "hasta = '2022-03-15'\n",
    "for item in terms:\n",
    "    try:\n",
    "        df = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(item + ' lang:es since:' +  desde + ' until:' + hasta + ' geocode:\"{}\"'.format(loc)).get_items(), 500))[['user', 'date', 'content']]\n",
    "        df['user_location'] =  df['user'].apply(lambda x: x['location'])\n",
    "    except KeyError:\n",
    "        df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "    dftemp = pd.concat([dftemp, df], axis=0)\n",
    "    print(item)\n",
    "\n",
    "df2 = dftemp[['date', 'content', 'user_location']]\n",
    "df2.to_csv(\"C://Tweets_2022.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a12944e",
   "metadata": {},
   "source": [
    "<h3>En esta celda se realiza el proceso de leer los todos los archivos con tuits que se descargaron, se concentran en un mismo dataframe, y se eliminan todos aquellos que son repetidos, preservando el primero. esto genera un archivo maestro con todos los tuits recolectados</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad38e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"C://NewFiles/*.csv\"\n",
    "df = pd.concat(map(pd.read_csv, glob.glob(ruta)))\n",
    "\n",
    "dfsorted = df.sort_values(by=['content'])\n",
    "dfdup = dfsorted[dfsorted.duplicated('content')]\n",
    "\n",
    "dfdup.drop_duplicates(subset =\"content\", keep = 'first', inplace = True)\n",
    "\n",
    "dfdup['fecha'] = pd.to_datetime(dfdup['date'])\n",
    "\n",
    "dfinal = dfdup.iloc[: , 1:]\n",
    "\n",
    "dfinal = dfinal.sort_values(by=\"fecha\")\n",
    "\n",
    "dfinal.reindex(columns=[\"fecha\", \"content\", \"user_location\"]).to_csv('C://Concentrado2.csv', index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889d4b5",
   "metadata": {},
   "source": [
    "<h3>A continuación, se toman todos los tuits y se construye la serie de tiempo del indicador diario del sentimiento agrupado</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ae041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "from pysentimiento import create_analyzer\n",
    "\n",
    "ruta = 'C://Concentrado2.csv'\n",
    "\n",
    "df = pd.read_csv(ruta, header=None)\n",
    "df.columns = [\"Fecha\", \"Tweet\",\"User_location\"]\n",
    "df['Tweet'] = df['Tweet'].str.translate({ord(c): \" \" for c in \"!@#$%^&*,.()\"\"[]{}';:/<>?\\|`’~-=_+\"})\n",
    "df['Tweet'] = df['Tweet'].str.replace('\\n',' ')\n",
    "\n",
    "analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
    "\n",
    "def getsent(sentscore):\n",
    "    valor = sentscore.output\n",
    "    #print(valor)\n",
    "    if valor == 'POS':\n",
    "        return sentscore.probas[valor]\n",
    "    elif valor == 'NEU':\n",
    "        return sentscore.probas[valor] * .5\n",
    "    else:\n",
    "        return sentscore.probas[valor] * -1\n",
    "\n",
    "def sentpol(texto):\n",
    "    salida = analyzer.predict(texto)\n",
    "    return getsent(salida)\n",
    "\n",
    "df['Polarity'] = df.apply(lambda row: sentpol(row['Tweet']), axis=1)\n",
    "\n",
    "df1 = df[['Fecha','User_location','Polarity']]\n",
    "\n",
    "df1 = df1.set_index(\"Fecha\")\n",
    "\n",
    "df1 = df1.reset_index(level=0)\n",
    "\n",
    "df2 = df1[['Fecha', 'Polarity']]\n",
    "df3 = df2.groupby(['Fecha']).mean()\n",
    "\n",
    "df3= df3.reset_index(level=0)\n",
    "\n",
    "df3.to_csv(\"C://SentpolAgrupado2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
